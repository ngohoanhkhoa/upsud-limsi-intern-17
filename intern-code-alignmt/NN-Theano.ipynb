{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "from theano import function, printing\n",
    "import theano\n",
    "\n",
    "from theano import config\n",
    "config.compute_test_value = 'raise'\n",
    "\n",
    "# updates = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 512)\n",
      "(9, 512)\n",
      "(9, 5)\n"
     ]
    }
   ],
   "source": [
    "class EmissionModel:\n",
    "    \"\"\" Simple emission model without CNN\n",
    "    word embedding layer -> ReLU layer -> softmax layer\n",
    "    \"\"\"\n",
    "    def init_weight_bias(self, n_x, n_y, seed=1402):\n",
    "        rng = np.random.RandomState(seed)\n",
    "        \n",
    "        w = theano.shared(\n",
    "            value=np.asarray(\n",
    "                rng.uniform(low=-1.0, high=1.0, size=(n_x, n_y)), \n",
    "                dtype=theano.config.floatX\n",
    "            ), \n",
    "            borrow=True\n",
    "        )\n",
    "        b = theano.shared(\n",
    "            value=np.asarray(\n",
    "                rng.uniform(low=-1.0, high=1.0, size=(n_x, 1)), \n",
    "                dtype=theano.config.floatX\n",
    "            ), \n",
    "            borrow=True,\n",
    "            broadcastable=(False,True)\n",
    "        )\n",
    "        \n",
    "        return w, b\n",
    "    \n",
    "    #[7,512]\n",
    "    def __init__(self, input_size, layer_size, output_size, epoch=1, batch=1, learning_rate = .01, seed=1412):\n",
    "        \n",
    "        self.epoch = 1\n",
    "        self.learning_rate = learning_rate\n",
    "        self.seed = seed\n",
    "        \n",
    "        x_input = T.matrix().astype(config.floatX)\n",
    "        x_input.tag.test_value = np.asarray([\n",
    "            [ 0.,  0.,  0.,  0.,  0.],\n",
    "            [ 0.,  0.,  0.,  1.,  0.],\n",
    "            [ 0.,  0.,  1.,  0.,  0.],\n",
    "            [ 0.,  0.,  0.,  0.,  1.],\n",
    "            [ 0.,  0.,  0.,  0.,  0.],\n",
    "            [ 0.,  0.,  0.,  0.,  0.],\n",
    "            [ 1.,  0.,  0.,  0.,  0.],\n",
    "            [ 0.,  0.,  0.,  0.,  0.],\n",
    "            [ 0.,  1.,  0.,  0.,  0.],\n",
    "            [ 0.,  0.,  0.,  0.,  0.]\n",
    "        ]).astype(x_input.dtype)\n",
    "        \n",
    "        # word embedding layer\n",
    "        self.w1, self.b1 = self.init_weight_bias(layer_size[0], input_size[0], seed) # 7, 10\n",
    "        word_embedding_layer = T.dot(self.w1, x_input) # [7, 10] * [10, 5] = [7, 5]\n",
    "        \n",
    "        # ReLU layer\n",
    "        self.w2, self.b2 = self.init_weight_bias(layer_size[1], layer_size[0], seed) # [512, 7] \n",
    "        z_relu_layer = T.dot(self.w2, word_embedding_layer) + self.b2 # [512, 7] * [7, 5] = [512, 5]\n",
    "        z_relu_layer_shape = T.shape(z_relu_layer)\n",
    "        z_reshaped_relu_layer = T.reshape(z_relu_layer, [z_relu_layer_shape[0]*z_relu_layer_shape[1], 1])\n",
    "        relu_layer = T.nnet.relu(z_reshaped_relu_layer)\n",
    "        relu_layer_reshaped = T.reshape(relu_layer, z_relu_layer_shape) # [512, 5]\n",
    "        \n",
    "        # Softmax layer\n",
    "        self.w3, self.b3 = self.init_weight_bias(output_size, layer_size[1], seed) # [9, 512], [9, 1]\n",
    "        z_softmax_layer = T.dot(self.w3, relu_layer_reshaped) + self.b3 # [9, 512] * [512, 5] = [9, 5]\n",
    "        log_softmax_layer = T.transpose(T.nnet.logsoftmax(T.transpose(z_softmax_layer))) # [9, 5]\n",
    "        \n",
    "        # calculate new gradient\n",
    "        posteriors = T.matrix().astype(config.floatX)\n",
    "        posteriors.tag.test_value = np.asarray([\n",
    "            [-0.15,  0.04, -0.26, -0.61, -0.93, -0.72, -0.15, -0.62,  0.62],\n",
    "            [ 0.07,  0.42,  0.11,  0.95, -0.86, -0.17, -0.22, -0.69, -0.55],\n",
    "            [-0.79,  0.3 ,  0.06, -0.79,  0.71,  0.86, -0.58,  0.38,  0.05],\n",
    "            [ 0.92, -0.33, -0.63,  0.99,  0.67, -0.79, -0.08,  0.64, -0.51],\n",
    "            [-0.08, -0.29,  0.87,  0.6 ,  0.31,  0.75,  0.38, -0.42,  0.11]\n",
    "        ]).astype(posteriors.dtype)\n",
    "        \n",
    "        cost = T.sum(T.transpose(posteriors) * log_softmax_layer)\n",
    "        dw1,dw2,dw3,db2,db3 = T.grad(cost=cost, wrt=[self.w1,self.w2,self.w3,self.b2,self.b3])\n",
    "\n",
    "        # Update w and b\n",
    "        updates = [\n",
    "            (self.w1, self.w1 - self.learning_rate * dw1), \n",
    "            (self.w2, self.w2 - self.learning_rate * dw2), \n",
    "#             (self.b2, self.b2 - self.learning_rate * db2),\n",
    "            (self.w3, self.w3 - self.learning_rate * dw3), \n",
    "#             (self.b3, self.b3 - self.learning_rate * db3)\n",
    "        ]\n",
    "        \n",
    "        # Compile model\n",
    "        self.test = theano.function(inputs=[x_input, posteriors], outputs=[dw2, log_softmax_layer]) \n",
    "        self.train = theano.function(inputs=[x_input, posteriors], outputs=[dw3, self.w3, log_softmax_layer], updates=updates)\n",
    "#         self.update_model = theano.function(inputs=[dw1,dw2,dw3,db2,db3], updates=updates)\n",
    "\n",
    "\n",
    "\n",
    "x = np.asarray([\n",
    "        [ 0.,  0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  1.,  0.],\n",
    "        [ 0.,  0.,  1.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  0.,  1.],\n",
    "        [ 0.,  0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  0.,  0.],\n",
    "        [ 1.,  0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  0.,  0.],\n",
    "        [ 0.,  1.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  0.,  0.]\n",
    "]).astype(config.floatX)\n",
    "\n",
    "posteriors = np.asarray([\n",
    "    [ 0.65, -0.32,  0.44, -0.04, -0.36, -0.81,  0.38, -0.84, -0.93],\n",
    "    [-0.41, -0.05,  0.96,  0.71,  0.08,  0.85,  0.12,  0.43, -0.08],\n",
    "    [-0.45,  0.04, -0.94,  0.41,  0.04, -0.3 ,  0.89, -0.09, -0.42],\n",
    "    [-0.19,  0.32,  0.  ,  0.02, -0.66, -0.41,  0.11, -0.05,  0.76],\n",
    "    [-0.32,  0.86,  0.09, -0.41, -0.57, -0.55, -0.85, -0.09, -0.27]\n",
    "]).astype(config.floatX)\n",
    "\n",
    "input_size = np.shape(x)\n",
    "d_embedding = 7\n",
    "layer_size = [d_embedding, 512]\n",
    "output_size = 9\n",
    "\n",
    "model = EmissionModel(input_size=input_size, layer_size=layer_size, output_size=output_size)\n",
    "print(np.shape(model.train(x, posteriors)[0]))\n",
    "print(np.shape(model.train(x, posteriors)[1]))\n",
    "print(np.shape(model.train(x, posteriors)[2]))\n",
    "# print(np.shape(model.evaluate_model(x)))\n",
    "# print(model.calculate_gradient(posteriors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.54168916 -1.95611656 -0.80767059 ...,  0.0150075  -1.01582396\n",
      "   0.24273789]\n",
      " [-0.73727387 -0.14424112 -0.14707598 ...,  0.35589412  0.5348444\n",
      "  -0.73343819]\n",
      " [ 1.35415351  0.5465734   0.2863223  ...,  1.95762193  0.72093588\n",
      "  -1.74118936]\n",
      " ..., \n",
      " [ 1.46260095 -0.90012485  0.12521118 ...,  2.85903215 -1.9474256\n",
      "  -1.77752268]\n",
      " [ 0.13362998 -0.61641389 -0.29073629 ...,  0.15156674 -0.06774771\n",
      "  -0.23446766]\n",
      " [ 0.1291711   0.28002194 -0.85524631 ...,  0.3341288   0.66809851\n",
      "   0.81234461]]\n",
      "\n",
      "[[ -90.02972412  -96.960289    -55.47723389  -61.02746582  -60.13369751]\n",
      " [ -44.75253296  -80.55125427  -57.31509781  -75.90653992  -76.2182312 ]\n",
      " [ -82.14437866 -109.63210297  -64.72553253  -94.17676544  -78.32346344]\n",
      " [ -81.82365417 -114.93276215  -85.48132324  -87.57543945  -72.5562973 ]\n",
      " [ -70.1398468   -75.07691193  -48.06699371  -43.70638275  -48.73448181]\n",
      " [ -51.00871277  -90.19257355  -50.91851807  -42.42922592  -47.50081635]\n",
      " [ -91.45339966 -107.12472534  -81.9734726   -76.25728607  -60.15761948]\n",
      " [   0.            0.            0.            0.            0.        ]\n",
      " [ -37.97032166  -85.74598694  -59.15186691  -89.18699646  -70.06443024]]\n"
     ]
    }
   ],
   "source": [
    "print(model.test(x, posteriors)[0])\n",
    "print(\"\")\n",
    "print(model.test(x, posteriors)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.           5.57754898  -9.18525124   0.7199952    0.           0.\n",
      "   -7.89429569   0.          -1.46904933   0.        ]\n",
      " [  0.           0.64274013 -13.09244156  -2.32017946   0.           0.\n",
      "   -0.86876476   0.         -11.55151653   0.        ]\n",
      " [  0.          -5.76161098  -4.97917032 -24.14969444   0.           0.\n",
      "  -25.05790901   0.           8.03187561   0.        ]\n",
      " [  0.           5.93158436  -5.77795553  10.00747681   0.           0.\n",
      "  -12.86737061   0.           5.82973385   0.        ]\n",
      " [  0.          -9.92446327   6.61135435   1.3710705    0.           0.\n",
      "   11.70029926   0.           0.85022926   0.        ]\n",
      " [  0.           7.5245719   18.20536995  18.03045273   0.           0.\n",
      "    6.99127102   0.          -6.09848785   0.        ]\n",
      " [  0.          14.53976059 -15.50912952 -15.97651482   0.           0.\n",
      "  -13.53068733   0.           7.26264811   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "posteriors = np.asarray([\n",
    "    [ 0.65, -0.32,  0.44, -0.04, -0.36, -0.81,  0.38, -0.84, -0.93],\n",
    "    [-0.41, -0.05,  0.96,  0.71,  0.08,  0.85,  0.12,  0.43, -0.08],\n",
    "    [-0.45,  0.04, -0.94,  0.41,  0.04, -0.3 ,  0.89, -0.09, -0.42],\n",
    "    [-0.19,  0.32,  0.  ,  0.02, -0.66, -0.41,  0.11, -0.05,  0.76],\n",
    "    [-0.32,  0.86,  0.09, -0.41, -0.57, -0.55, -0.85, -0.09, -0.27]\n",
    "]).astype(config.floatX)\n",
    "\n",
    "print(model.test(x, posteriors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65, -0.32,  0.44, -0.04, -0.36, -0.81,  0.38, -0.84, -0.93],\n",
       "       [-0.41, -0.05,  0.96,  0.71,  0.08,  0.85,  0.12,  0.43, -0.08],\n",
       "       [-0.45,  0.04, -0.94,  0.41,  0.04, -0.3 ,  0.89, -0.09, -0.42],\n",
       "       [-0.19,  0.32,  0.  ,  0.02, -0.66, -0.41,  0.11, -0.05,  0.76],\n",
       "       [-0.32,  0.86,  0.09, -0.41, -0.57, -0.55, -0.85, -0.09, -0.27]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(low=-100, high=100, size=(5, 9))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
